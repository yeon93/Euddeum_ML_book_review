{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN(recurrent neural network, 순환신경망)\n",
    "앞서 배운 신경망들은 모든 신호가 오직 출력층 방향으로만 향하고 있었다.  \n",
    "이런 신경망들을 feedforward 신경망이라고 하는데, 한 시점의 이미지나 정보만을 이용한다는 단점이 있다.  \n",
    "\n",
    "\n",
    "RNN은 시간에 따라 순차적으로 제공되는 정보를 다룰 수 있는 신경망으로, 다양한 분야에서 널리 이용되고 있다.  \n",
    "RNN을 구성하는 뉴런들은 활성화함수를 통해 나온 출력이 다시 자기자신에게 입력으로 제공되는 구조이다.  \n",
    "이런 뉴런은 시간의 흐름에 따라 연속적으로 발생하는 신호를 보고, 다음 신호를 예측하는 일에 좋은 성능을 보인다.  \n",
    "RNN의 대표적 응용사례는 네이버의 파파고 같은 기계번역 프로그램이다.  \n",
    "입력과 출력 모두 sequence로, 글자나 단어들이 순서를 가지고 연속적으로 나타난다.  \n",
    "1:m, n:1, n:m 의 다양한 기법이 있다.\n",
    "\n",
    "\n",
    "+ 첫번째 cell : x1 입력 => h1 출력\n",
    "+ 두번째 cell : x2 입력 + h1 => h2\n",
    "+ 세번째 cell : x3 입력 + h2 => h3 ....\n",
    "\n",
    "\n",
    "모든 layer(=순환cell)는 이전 상태 정보를 보존하는 기능과, 다음 층으로 정보를 전달하는 구조를 가지며,  \n",
    "신호가 전달될 때는 학습을 통해 변경되는 weight가 곱해져서 전달된다.\n",
    "\n",
    "\n",
    "하나의 셀은 (자신의 이전 셀에서 얻은 입력 + 새롭게 제공된 입력)을 하나의 활성화함수에 제공한다.  \n",
    "활성화함수는 일반적으로 tanh를 사용하며, 그 결과는 노드의 출력 h가 되어 순환edge를 통해 자신에게 feedback된다.\n",
    "+ tanh를 사용하는 이유?\n",
    "    + ReLU를 사용하면 feedback 구조 때문에 신호가 지나치게 커지는 overflow가 발생할 수 있다.\n",
    "    + tanh, sigmoid의 경우 값이 특정 범위를 넘지 못하게 되어있어 위 문제를 피할 수 있다.\n",
    "    + tanh가 sigmoid보다 기울기소실 문제를 더 잘 해결한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow로 단순 RNN 모델 만들기\n",
    "+ 입력 : [0.0, 0.1, 0.2] 처럼 3개의 원소를 가지는 시퀀스 데이터\n",
    "+ 목표값 : 0.3 처럼 하나의 실수 레이블 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. ]\n",
      " [0.1]\n",
      " [0.2]] 0.3\n",
      "[[0.1]\n",
      " [0.2]\n",
      " [0.3]] 0.4\n",
      "[[0.2]\n",
      " [0.3]\n",
      " [0.4]] 0.5\n",
      "[[0.3]\n",
      " [0.4]\n",
      " [0.5]] 0.6\n",
      "[[0.4]\n",
      " [0.5]\n",
      " [0.6]] 0.7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "size, seq_len = 100, 3\n",
    "\n",
    "X = np.empty(shape=(size, seq_len, 1))   #(100, 3, 1)\n",
    "Y = np.empty(shape=(size,))              #(100,)\n",
    "\n",
    "for i in range(size):\n",
    "    c = np.linspace(i/10, (i+seq_len-1)/10.0, seq_len)   #(3, )\n",
    "    X[i] = c[:, np.newaxis]   #(3, 1)\n",
    "    Y[i] = (i+seq_len)/10\n",
    "    \n",
    "for i in range(5):\n",
    "    print(X[i], Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 20)                440       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 461\n",
      "Trainable params: 461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([keras.layers.SimpleRNN(units=20, input_shape=[3,1],  #layer에 있는 뉴런 유닛의 수, 입력형태는 [seq_len,1]로 각각이 모두 출력을 발생시킴\n",
    "                                                 return_sequences=False),      #출력으로 시간시리즈에 걸친 시퀀스 전체를 출력할지\n",
    "                          keras.layers.Dense(1)])   #20개의 유닛의 각 출력들을 하나의 레이블 값으로 만들기 위해 출력노드 개수를 1로 지정\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(유닛 20개 x 순환에지 20개) + 입력을 각 유닛에 보내는 연결 20개 + 각 유닛의 출력을 위한 연결 20개  \n",
    "=> 이 신경망을 위한 파라미터는 총 440개\n",
    "\n",
    "이 계층의 출력 20개 + 편향 1개  \n",
    "=> 출력을 위한 연결망을 위한 파라미터는 총 21개  \n",
    "\n",
    "\n",
    "=> total params : 461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb88e109d514f8fe4882139470fc892eb0cca4de07a5bc3f5da4dc1ae8fba1ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
