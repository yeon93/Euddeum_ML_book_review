{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다층 퍼셉트론의 한계\n",
    "다층 퍼셉트론의 학습이 가능해지면서 층을 깊이 쌓기만 하면 복잡한 기능을 하는 신경망 모델을 만들어낼 수 있을 것이라 기대했다.  \n",
    "하지만 층을 깊이 쌓을수록 더 정교해지기보다는 학습을 하지 못하는 모델이 되어갔다.  \n",
    "이것은 경사하강법을 통해 오차를 줄여가는 과정이 제대로 동작하지 않았기 때문인데,  \n",
    "출력 근처에서는 오차를 반영하여 가중치를 조절했지만, 역전파될수록 점점 신호가 소실되는 vanishing gradient 문제가 발생하거나  \n",
    "역전파될수록 점점 신호가 커지는 exploding gradient 문제가 발생한 것이다.  \n",
    "\n",
    "#### 범인1. 활성화함수 \n",
    "+ sigmoid 함수는 비대칭 함수로, 값이 0 또는 1에 가까워지면 그 미분값은 0에 가까워지므로,  \n",
    "아래 단계로 오차를 제대로 전파하지 못하고, 결국 학습이 제대로 이루어지지 않는다.  \n",
    "=> 활성화함수를 tanh같은 대칭 함수를 사용해 활성화함수 값이 0이어도 오차를 잘 전달해 줄 수 있도록 한다.\n",
    "+ 과거 여러 층을 겹쳐 신경망을 구현 시 일반적으로 사용하던 sigmoid 함수 말고 다양한 활성화함수를 적용하는 시도들이 등장했다.\n",
    "+ ReLU는 양수 입력은 그대로 내보내고, 음수 입력은 0을 출력해 기울기 소실 문제는 피하면서 계산 효율이 높다.  \n",
    "\n",
    "#### 범인2. 가중치 초기화 방법\n",
    "+ 각 계층의 노드 수가 달라지면, 입력->출력의 순전파 신호, 출력->입력의 오차 역전파 신호의 분산이 왜곡돼 전달되므로 기울기소실/폭발 문제가 발생한다.\n",
    "+ 따라서 각 은닉층의 크기가 동일하면 좋지만, 실제로 그러긴 힘들다. \n",
    "+ Keras에서는 디폴트로 glorot_uniform(=Xavier initialization) 방법으로 초기화해준다.\n",
    "+ 다양한 활성화함수를 시도해보면서 초기화는 활성화함수의 특성에 따라 다르게 설정되어야 한다는 것도 알게 되었다.\n",
    "+ 신경망의 층이 늘어날수록 ReLU와 같은 정류화 함수(rectifiers)들이 더 잘 동작하는 것도 알게 되었다.\n",
    "+ ReLU 활성화함수를 사용할 때 glorot_uniform보다 He(허) 초기화가 더 빠르게 수렴한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)      #60000개의 28*28 데이터\n",
    "print(x_train[0].shape)   #0-255 사이의 값 28*28(784)개\n",
    "print(y_train.shape)      #레이블은 0-9 사이의 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  3 18 18 18126136175 26166255247127  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 30 36 94154170253253253253253225172253242195 64  0  0  0  0\n",
      "  0  0  0  0  0  0  0 49238253253253253253253253253251 93 82 82 56 39  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0 18219253253253253253198182247241  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 80156107253253205 11  0 43154  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 14  1154253 90  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0139253190  2  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 11190253 70  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 35241225160108  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0 81240253253119 25  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 45186253253150 27  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16 93252253187  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0249253249 64  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 46130183253253207  2  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 39148229253253253250182  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 24114221253253253253201 78  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 23 66213253253253253198 81  2  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 18171219253253253253195 80  9  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0 55172226253253253253244133 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0136253253253212135132 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n"
     ]
    }
   ],
   "source": [
    "#x_train[0]의 값들을 모두 출력해보자\n",
    "num = x_train[0]\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        print('{:3d}'.format(num[i][j]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'label = {y_train[0]}')\n",
    "plt.imshow(num, cmap='Greys', interpolation='nearest');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터로 Keras 이용하기\n",
    "1. x_train 데이터를 심층 신경망 모델에 넣어 y_train의 레이블로 인식하도록 학습시키기\n",
    "2. 이 때 노드의 활성화함수, 학습을 위한 최적화함수, 손실함수, 측정방법 지정하기\n",
    "    + 분류문제에서 출력층의 최적화함수는 softmax(가중치 벡터를 클래스별 확률값(0-1)으로 변환)\n",
    "3. 학습된 모델에 x_test 데이터를 넣어 모델의 정확도 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2262 - accuracy: 0.9344\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0940 - accuracy: 0.9722\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0621 - accuracy: 0.9813\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0454 - accuracy: 0.9862\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0336 - accuracy: 0.9893\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0251 - accuracy: 0.9918\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0186 - accuracy: 0.9941\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0173 - accuracy: 0.9942\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0139 - accuracy: 0.9953\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0103 - accuracy: 0.9969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29233109cd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0-255 사이 값을 0-1 사이 값이 되도록 정규화\n",
    "#인공신경망의 전체 수식에서 사용되는 값이 float값이기 때문에 정규화를 통해 입력을 float로 맞춰 더 나은 결과를 얻을 수 있음\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "model = keras.models.Sequential([keras.layers.Flatten(input_shape=(28,28)),       #28*28 배열을 784*1로 펼침ㅠ\n",
    "                                 keras.layers.Dense(256, activation='relu'),\n",
    "                                 keras.layers.Dense(10, activation='softmax')])   #레이블이 10개로 분류해야하기 때문\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "#입력 784개(+편향값 1개) * 은닉층 256개 = 200960\n",
    "#은닉층 256개(+편향값 1개) * 은닉층 10개 = 2570\n",
    "#200960 + 2570 = 총 253530개의 파라미터를 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08771241456270218, 0.9782999753952026]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)  #각각 loss, compile의 metrics(지금은 accuracy)를 나타냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원핫인코딩\n",
    "벡터 출력값이 스칼라 형식의 정답과 얼마만큼 차이나는지 정량화하기 어렵기 때문에 원핫인코딩을 사용할 수 있다.\n",
    "1. 각 레이블에 고유 인덱스를 부여한다.\n",
    "2. 표현하고자하는 레이블의 인덱스 위치에 1, 나머지 인덱스에 0을 부여한다.\n",
    "\n",
    "=> keras.utils의 to_categorical 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 : [0 1 2 3 4]\n",
      "인코딩 후 :\n",
      " [[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "data = np.array([0,1,2,3,4])\n",
    "print('원본 데이터 :', data)\n",
    "\n",
    "encoded_data = to_categorical(data)\n",
    "print('인코딩 후 :\\n', encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맞을 확률이 높을 때 MSE : 0.016201599999999997\n",
      "맞을 확률이 낮을 때 MSE : 0.25564\n"
     ]
    }
   ],
   "source": [
    "#정답레이블이 3일 때, 모델이 출력한 예측(벡터)와 비교해 오차 구해보기\n",
    "target = np.array([0, 0, 0, 1, 0])\n",
    "correct_y_pred = np.array([0.005, 0.173, 0.035, 0.777, 0.01])   #3의 확률이 77.7%로 가장 높긴 함\n",
    "wrong_y_pred = np.array([0.2, 0.3, 0.4, 0.01, 0.09])\n",
    "\n",
    "def mse(y, t):  #평균제곱오차\n",
    "    return ((y-t)**2).mean()\n",
    "\n",
    "print('맞을 확률이 높을 때 MSE :', mse(correct_y_pred, target))\n",
    "print('맞을 확률이 낮을 때 MSE :', mse(wrong_y_pred, target))   #정답에서 많이 벗어날수록 큰 오차값 출력 => 가중치 업데이트를 더 많이해 학습이 제대로 이루어질 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_entropy_error\n",
    "+ 분류모델의 레이블이 원핫인코딩으로 구성된 경우에만 사용 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맞을 확률이 높을 때 CEE : 0.2523147999143692\n",
      "맞을 확률이 낮을 때 CEE : 4.605160186038091\n",
      "비율 : 18.251645117928057\n",
      "\n",
      "맞을 확률이 높을 때 MSE : 0.016201599999999997\n",
      "맞을 확률이 낮을 때 MSE : 0.25564\n",
      "비율 : 15.778688524590166\n"
     ]
    }
   ],
   "source": [
    "def cee(y, t):\n",
    "    delta = 1e-7   #분모가 0이 되지 않도록 작은 마진값 설정\n",
    "    return -np.sum(t * np.log(y+delta))\n",
    "\n",
    "target = np.array([0, 0, 0, 1, 0])\n",
    "correct_y_pred = np.array([0.005, 0.173, 0.035, 0.777, 0.01])   #3의 확률이 77.7%로 가장 높긴 함\n",
    "wrong_y_pred = np.array([0.2, 0.3, 0.4, 0.01, 0.09])\n",
    "\n",
    "print('맞을 확률이 높을 때 CEE :', cee(correct_y_pred, target))\n",
    "print('맞을 확률이 낮을 때 CEE :', cee(wrong_y_pred, target))  \n",
    "print('비율 :', cee(wrong_y_pred, target) / cee(correct_y_pred, target))\n",
    "print()\n",
    "print('맞을 확률이 높을 때 MSE :', mse(correct_y_pred, target))\n",
    "print('맞을 확률이 낮을 때 MSE :', mse(wrong_y_pred, target))\n",
    "print('비율 :', mse(wrong_y_pred, target) / mse(correct_y_pred, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "맞았을 때/틀렸을 때의 오차 비율을 확인해보면 cross entropy error를 사용했을 때가 더 높다.  \n",
    "학습은 오차를 줄여나가는 과정이기 때문에, 더 큰 패널티를 부여하는 cross entropy error를 신경망의 오차로 사용하면  \n",
    "학습속도를 더 높일 수 있고, 오답 레이블과의 오차는 구하지 않으므로 분류할 레이블이 많아질수록 계산량이 줄어든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb88e109d514f8fe4882139470fc892eb0cca4de07a5bc3f5da4dc1ae8fba1ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
